# Road Lane Network Graph Open
This repository contain code to reproduce results in the paper "Learning a Model for Inferring a Spatial Road Lane Network Graph using Self-Supervision" to be published at ITSC 2021.

### Dependencies
Python3
  - version: 3.6
  - packages:
    - FILL IN (pipreqs --> requirements.txt)

pip install -r requirements.txt

Ref:  https://stackoverflow.com/questions/46419607/how-to-automatically-install-required-packages-from-a-python-script-as-necessary/46419642

### TL;DR

# How to use

## 1. Create examples

Artificial 'raw samples' are created using `artificial_sample_gen.py`. This program loads samples from a directory containing semantic road scene context images (`standard_intersection_1.png`, etc.) and individual trajectories are generated according to user mouse clicks. Note that the click interval ought to be somewhat dense to allow trajectories to naturally curve during the sample warping process. The trajectories should be reasonably straight, mimicking actual human driving trajectories.

When using `artificial_sample_gen.py`, pressing 'n' saves the finished sample and prepares for the next sample. Pressing 'c' cancels the current sample to start from scratch. Pressing 'q' quits the current scene and goes to the next one. 

Example for generating samples for `samples_intersection_1`:
```
python data_gen/artificial/artificial_sample_gen.py data_gen/artificial/samples_intersection_1/
```

Raw samples used in the paper are provided pregenerated in their corresponding sample directory inside `data_gen/artificial/`.

## 2. Generate training dataset

The previously generated 'raw samples' are converted into 'training samples' and 'evaluation samples' by programs located in `datasets/`.

A training sample contain a single example trajectory and are used for training. Training samples can be geometrically augmented, meaning each sample feed to the model during training is unique.

1. Generate training samples

```
python datasets/train_set_gen.py 
```
A new directory `datasets/training_samples/` is created, containing training samples.

2. To speed up the training process, one can choose to pregenerate a large number of such augmented samples, which can be read directly by the dataloader during training. The paper uses a set of 1 million pregenerated samples.

```
python datasets/pregen_dataset.py 
```

Generated training samples (both ordinary and pregenerated ones) can be visualized by running
```
python viz/viz_dataset.py datasets/training_samples/ --augment
```

All training and evaluation samples used in the paper are provided pregenerated in their corresponding directory inside `datasets/`. The set of pregenrated training samples used for training in the paper can be downloaded from a [Google Drive directory](https://drive.google.com/drive/folders/1SnScGkU1x_yXnkWH1fGBatjK6zSGC9pG?usp=sharing) as `datasets/training_samples_pregen.tar`.

## 3. Generate evaluation datasets

1. An evaluation sample are generated by superimposing all identically augmented example trajectories of a scene, representing the ideal solution which is used to evaluate the quality of the model output.

```
python datasets/test_sample_gen.py
```

2. Evaluation sets are generated by arranging samples from the previously generated test samples, split into layouts seen during training (`training_eval/`) as well as new layouts (`test_eval/`)

```
python datasets/eval_set_gen.py
```

Generated test samples can be visualized by running
```
python viz/viz_test_sample.py datasets/test_samples/<scene_dir>/ <sample_idx>`
```

## 4. Train model

## 5. Inference

## File structure
